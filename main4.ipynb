{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load dataset\n",
    "csv_file = \"C:/Users/malli/Downloads/large_multilingual_translation_dataset.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Available translation models\n",
    "language_pairs = {\n",
    "    \"English to French\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
    "    \"English to Spanish\": \"Helsinki-NLP/opus-mt-en-es\",\n",
    "    \"English to German\": \"Helsinki-NLP/opus-mt-en-de\",\n",
    "    \"French to English\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
    "    \"Spanish to English\": \"Helsinki-NLP/opus-mt-es-en\",\n",
    "    \"German to English\": \"Helsinki-NLP/opus-mt-de-en\"\n",
    "}\n",
    "\n",
    "# Streamlit App Interface\n",
    "st.title(\"Real-Time Language Translation (NMT)\")\n",
    "st.write(\"Bridging Language Barriers with Neural Machine Translation\")\n",
    "\n",
    "# User Input\n",
    "selected_pair = st.selectbox(\"Select Language Pair\", list(language_pairs.keys()))\n",
    "user_text = st.text_area(\"Enter text to translate:\")\n",
    "\n",
    "if st.button(\"Translate\") and user_text:\n",
    "    source_lang, target_lang = selected_pair.split(\" to \")\n",
    "    \n",
    "    # Check dataset for translation\n",
    "    if source_lang in df.columns and target_lang in df.columns:\n",
    "        match = df[df[source_lang].str.lower() == user_text.lower()]\n",
    "        if not match.empty:\n",
    "            translated_text = match[target_lang].values[0]\n",
    "            st.subheader(\"Translated Text (From Dataset):\")\n",
    "            st.success(translated_text)\n",
    "        else:\n",
    "            st.write(\"Translation not found in dataset. Using NMT model...\")\n",
    "            use_model = True\n",
    "    else:\n",
    "        use_model = True\n",
    "\n",
    "    # Use model if dataset lookup fails\n",
    "    if 'use_model' in locals() and use_model:\n",
    "        model_name = language_pairs[selected_pair]\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Tokenize and Translate\n",
    "        inputs = tokenizer([user_text], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        translated = model.generate(**inputs)\n",
    "        translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Display Output\n",
    "        st.subheader(\"Translated Text (Using Model):\")\n",
    "        st.success(translated_text)\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.write(\"Developed with ‚ù§ using Hugging Face Transformers, Streamlit & Dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
